"""
í†µí•© í‚¤ìœ„ ë†ì¥ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ
- ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘
- ì ì‚°ì˜¨ë„ ê³„ì‚°
- ìƒìœ¡ ë‹¨ê³„ ìë™ ê°ì§€
"""

import os
import json
import time
import requests
from datetime import datetime, timedelta

# í™˜ê²½ë³€ìˆ˜
ECOWITT_APP_KEY = os.environ.get('ECOWITT_APP_KEY')
ECOWITT_API_KEY = os.environ.get('ECOWITT_API_KEY')
ECOWITT_MAC = os.environ.get('ECOWITT_MAC')

# íŒŒì¼ ê²½ë¡œ
DATA_DIR = "data"
SENSOR_FILE = os.path.join(DATA_DIR, "sensor_history.json")
GDD_FILE = os.path.join(DATA_DIR, "gdd_data.json")
PHENOLOGY_FILE = os.path.join(DATA_DIR, "phenology.json")

def get_daily_data(date_str):
    """ECOWITT ì¼ë³„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    try:
        url = "https://api.ecowitt.net/api/v3/device/history"
        t = str(int(time.time() * 1000))
        
        params = {
            "application_key": ECOWITT_APP_KEY,
            "api_key": ECOWITT_API_KEY,
            "mac": ECOWITT_MAC,
            "start_date": date_str,
            "end_date": date_str,
            "cycle_type": "daily",
            "call_back": "all",
            "temp_unitid": "1",
            "t": t
        }
        
        print(f"ğŸ“¡ Fetching {date_str}...")
        response = requests.get(url, params=params, timeout=15)
        
        if response.status_code == 200:
            result = response.json()
            if result.get("code") == 0 and result.get("data", {}).get("list"):
                print(f"âœ… Success")
                return result["data"]
        
        print(f"âš ï¸  No data")
        return None
            
    except Exception as e:
        print(f"âŒ Error: {e}")
        return None

def parse_daily_data(data, date_str):
    """ë°ì´í„° íŒŒì‹±"""
    try:
        day_data = data["list"][0]
        date_obj = datetime.strptime(date_str, "%Y-%m-%d")
        
        def safe_get(d, key, default=0.0):
            try:
                val = d.get(key, {})
                if isinstance(val, dict):
                    return float(val.get("value", default))
                return float(val) if val is not None else default
            except:
                return default
        
        return {
            "date": date_str,
            "month": date_obj.month,
            "day_of_year": date_obj.timetuple().tm_yday,
            "temp_2dong": safe_get(day_data, "temp_ch1_avg"),
            "temp_3dong": safe_get(day_data, "temp_ch3_avg"),
            "temp_soil": safe_get(day_data, "temp_ch2_avg"),
            "moisture_2dong": safe_get(day_data, "soilmoisture_ch1_avg"),
            "moisture_3dong": safe_get(day_data, "soilmoisture_ch2_avg"),
            "outdoor_temp": safe_get(day_data, "outdoor_temp_avg"),
            "outdoor_temp_max": safe_get(day_data, "outdoor_temp_max"),
            "outdoor_temp_min": safe_get(day_data, "outdoor_temp_min"),
            "outdoor_humid": safe_get(day_data, "outdoor_humidity_avg"),
        }
        
    except Exception as e:
        print(f"âŒ Parse error: {e}")
        return None

def load_json(filepath):
    """JSON ë¡œë“œ"""
    try:
        if os.path.exists(filepath):
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        return [] if filepath != PHENOLOGY_FILE else {}
    except:
        return [] if filepath != PHENOLOGY_FILE else {}

def save_json(filepath, data):
    """JSON ì €ì¥"""
    try:
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"âŒ Save error: {e}")
        return False

def save_sensor_data(parsed_data):
    """ì„¼ì„œ ë°ì´í„° ì €ì¥"""
    history = load_json(SENSOR_FILE)
    date_str = parsed_data["date"]
    
    existing_idx = None
    for idx, record in enumerate(history):
        if record.get("date") == date_str:
            existing_idx = idx
            break
    
    if existing_idx is not None:
        history[existing_idx] = parsed_data
        print(f"ğŸ”„ Updated: {date_str}")
    else:
        history.append(parsed_data)
        print(f"â• Added: {date_str}")
    
    history.sort(key=lambda x: x["date"])
    return save_json(SENSOR_FILE, history)

def calculate_gdd(parsed_data, base_temp=10.0, shock_threshold=8.0):
    """ì ì‚°ì˜¨ë„ ê³„ì‚°"""
    gdd_records = load_json(GDD_FILE)
    date_str = parsed_data["date"]
    outdoor_temp = parsed_data["outdoor_temp"]
    
    for record in gdd_records:
        if record.get("date") == date_str:
            print(f"âš ï¸  GDD exists")
            return True
    
    yesterday_gdd = 0
    stress_days = 0
    
    if gdd_records:
        last = gdd_records[-1]
        yesterday_gdd = last.get("accumulated_gdd", 0)
        stress_days = last.get("stress_days_remaining", 0)
    
    daily_gdd = 0
    recovery_penalty = 0.5
    
    if outdoor_temp < shock_threshold:
        daily_gdd = 0
        stress_days = 3
        print(f"â„ï¸  Shock: {outdoor_temp}Â°C")
    elif stress_days > 0:
        raw_gdd = max(0, outdoor_temp - base_temp)
        daily_gdd = raw_gdd * recovery_penalty
        stress_days -= 1
    else:
        daily_gdd = max(0, outdoor_temp - base_temp)
    
    accumulated_gdd = yesterday_gdd + daily_gdd
    
    new_record = {
        "date": date_str,
        "outdoor_temp": outdoor_temp,
        "daily_gdd": round(daily_gdd, 2),
        "accumulated_gdd": round(accumulated_gdd, 2),
        "stress_days_remaining": stress_days,
        "is_shock": outdoor_temp < shock_threshold
    }
    
    gdd_records.append(new_record)
    
    if save_json(GDD_FILE, gdd_records):
        print(f"ğŸ“ˆ GDD: +{daily_gdd:.2f} â†’ {accumulated_gdd:.2f}")
        
        # ìƒìœ¡ ë‹¨ê³„ ìë™ ê°ì§€
        detect_phenology_stage(accumulated_gdd, date_str)
        
        return True
    return False

def detect_phenology_stage(current_gdd, date_str):
    """ìƒìœ¡ ë‹¨ê³„ ìë™ ê°ì§€ ë° ê¸°ë¡"""
    phenology = load_json(PHENOLOGY_FILE)
    
    year = datetime.strptime(date_str, "%Y-%m-%d").year
    year_str = str(year)
    
    if year_str not in phenology:
        phenology[year_str] = {}
    
    year_data = phenology[year_str]
    
    # ë°œì•„ ê°ì§€ (GDD 200)
    if current_gdd >= 200 and "bud_break" not in year_data:
        year_data["bud_break"] = {
            "date": date_str,
            "gdd_at_event": round(current_gdd, 2),
            "auto_detected": True
        }
        print(f"ğŸŒ± ë°œì•„ ê°ì§€!")
    
    # ê°œí™” ê°ì§€ (GDD 750)
    if current_gdd >= 750 and "flowering_start" not in year_data:
        year_data["flowering_start"] = {
            "date": date_str,
            "gdd_at_event": round(current_gdd, 2),
            "auto_detected": True
        }
        print(f"ğŸŒ¸ ê°œí™” ê°ì§€!")
    
    save_json(PHENOLOGY_FILE, phenology)

def backfill_missing_dates():
    """ìµœê·¼ 7ì¼ ëˆ„ë½ ë°ì´í„° ë³´ì¶©"""
    print("\nğŸ” Checking missing dates...")
    
    history = load_json(SENSOR_FILE)
    existing_dates = set(r["date"] for r in history)
    
    filled = 0
    for i in range(1, 8):
        check_date = (datetime.now() - timedelta(days=i)).strftime("%Y-%m-%d")
        
        if check_date not in existing_dates:
            print(f"ğŸ“¥ Backfill: {check_date}")
            data = get_daily_data(check_date)
            
            if data:
                parsed = parse_daily_data(data, check_date)
                if parsed and save_sensor_data(parsed):
                    calculate_gdd(parsed)
                    filled += 1
                    time.sleep(2)
    
    print(f"âœ… Backfilled: {filled} dates")

def main():
    print("="*60)
    print("ğŸ¥ í‚¤ìœ„ ë†ì¥ í†µí•© ë°ì´í„° ìˆ˜ì§‘")
    print("="*60)
    print(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    if not all([ECOWITT_APP_KEY, ECOWITT_API_KEY, ECOWITT_MAC]):
        print("âŒ API credentials missing")
        return False
    
    yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
    print(f"ğŸ¯ Target: {yesterday}\n")
    
    # ì–´ì œ ë°ì´í„° ìˆ˜ì§‘
    data = get_daily_data(yesterday)
    
    if not data:
        print("âš ï¸  Fetch failed, trying backfill...")
        backfill_missing_dates()
        return True
    
    parsed = parse_daily_data(data, yesterday)
    
    if not parsed:
        print("âŒ Parse failed")
        return False
    
    if not save_sensor_data(parsed):
        print("âŒ Save failed")
        return False
    
    if not calculate_gdd(parsed):
        print("âŒ GDD failed")
        return False
    
    backfill_missing_dates()
    
    # í†µê³„
    sensor_count = len(load_json(SENSOR_FILE))
    gdd_count = len(load_json(GDD_FILE))
    
    print("\n" + "="*60)
    print("ğŸ“Š SUMMARY")
    print("="*60)
    print(f"âœ… Sensor records: {sensor_count}")
    print(f"âœ… GDD records: {gdd_count}")
    print(f"âœ… Files saved to: {DATA_DIR}/")
    print("="*60)
    
    return True

if __name__ == "__main__":
    try:
        success = main()
        exit(0 if success else 1)
    except Exception as e:
        print(f"\nâŒ FATAL: {e}")
        import traceback
        traceback.print_exc()
        exit(1)
